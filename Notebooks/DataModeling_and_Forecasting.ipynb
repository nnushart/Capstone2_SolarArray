{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "import calplot\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from pmdarima.arima import auto_arima\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames\n",
    "\n",
    "'''\n",
    "sp_df = pd.read_csv('../Data/Proc/sp_df.csv')\n",
    "p1_dt = pd.read_csv('../Data/Proc/p1_dt.csv')\n",
    "p2_dt = pd.read_csv('../Data/Proc/p2_dt.csv')\n",
    "\n",
    "train_11 = pd.read_csv('../Data/Proc/train_11.csv')\n",
    "test_11 = pd.read_csv('../Data/Proc/test_11.csv')\n",
    "\n",
    "train_14.to_csv('../Data/Proc/train_14.csv', index=False)\n",
    "test_14.to_csv('../Data/Proc/test_14.csv', index=False)\n",
    "train_24.to_csv('../Data/Proc/train_24.csv', index=False)\n",
    "test_24.to_csv('../Data/Proc/test_24.csv', index=False)\n",
    "train_34.to_csv('../Data/Proc/train_34.csv', index=False)\n",
    "test_34.to_csv('../Data/Proc/test_34.csv', index=False)\n",
    "train_44.to_csv('../Data/Proc/train_44.csv', index=False)\n",
    "test_44.to_csv('../Data/Proc/test_44.csv', index=False)\n",
    "\n",
    "train_fcst1.to_csv('../Data/Proc/train_fcst1.csv', index=False)\n",
    "test_fcst1.to_csv('../Data/Proc/test_fcst1.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_df.head(), p1_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create P1 subset based on datetime\n",
    "\n",
    "p1_pred = p1_df.copy()\n",
    "p1_pred = p1_pred.groupby('DATE_TIME').sum()\n",
    "p1_pred = p1_pred['DAILY_YIELD'][-]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model = auto_arima(train,\n",
    "                         start_p=0,d=1,start_q=0,\n",
    "                         max_p=4,max_d=4,max_q=4,\n",
    "                         start_P=0,D=1,start_Q=0,\n",
    "                         max_P=1,max_D=1,max_Q=1,m=96,\n",
    "                         seasonal=True,\n",
    "                         error_action='warn',trace=True,\n",
    "                         supress_warning=True,stepwise=True,\n",
    "                         random_state=20,n_fits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen2=gen_1.copy()\n",
    "pred_gen2=pred_gen2.groupby('DATE_TIME')['DAILY_YIELD'].sum().reset_index()\n",
    "pred_gen2.rename(columns={'DATE_TIME':'ds','DAILY_YIELD':'y'},inplace=True)\n",
    "pred_gen2.plot(x='ds',y='y',figsize=(17,5))\n",
    "plt.legend('')\n",
    "plt.title('DAILY_YIELD',size=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(pred_gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = [pred_gen2['ds'].iloc[-1:] + DateOffset(minutes=x) for x in range(0,2910,15) ]\n",
    "time1=pd.DataFrame(future).reset_index().drop('index',1)\n",
    "time1.rename(columns={3157:'ds'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline=pd.DataFrame(pred_gen2['ds'])\n",
    "fut=timeline.append(time1,ignore_index=True)\n",
    "fut.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(forecast,figsize=(15,7))\n",
    "plt.title('ok')\n",
    "plt.legend(labels=['Original data','Prophet Forecast'])\n",
    "plt.title('Prophet Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
